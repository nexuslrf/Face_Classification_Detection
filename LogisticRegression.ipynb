{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math for Logistic:\n",
    "$$y \\in \\{-1,+1\\}$$\n",
    "\n",
    "$$h_{\\theta}(x) = sigmoid(\\theta^Tx) = \\frac{1}{1+exp(-\\theta^Tx)}$$\n",
    "\n",
    "#### prob distribution for $y$\n",
    "\n",
    "$$p(y|X;\\theta) = h_{\\theta}(yX)$$\n",
    "\n",
    "#### MLE:\n",
    "\n",
    "$$\\max L(\\theta) = \\prod_{i=1}^{m}h_{\\theta}(y^{(i)}x^{(i)})$$\n",
    "\n",
    "#### Loss function:\n",
    "\n",
    "$$\\mathcal{l}(\\theta) = \\log L(\\theta) = - \\sum_{i=1}^{m}\\log(1+\\exp(-y^{(i)}\\theta^Tx^{(i)}))$$\n",
    "\n",
    "#### Gradient  of loss:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\theta}\\mathcal l(\\theta) = (1-h_{\\theta}(yX)) \\cdot yX$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "d_sigmoid = lambda x: sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticRegression():\n",
    "    def __init__(self, dim, alpha=1.0, zero_init=False):\n",
    "        self.dim = dim+1\n",
    "        self.alpha = alpha\n",
    "        self.theta = np.zeros([dim+1]) if zero_init else np.random.randn(dim+1)\n",
    "#         self.theta[0] = 0\n",
    "        self.sigmoid = lambda x: 1/(1+np.exp(-x))\n",
    "        self.h = lambda x: self.sigmoid(np.dot(self.theta,x))\n",
    "    \n",
    "    def fit(self, X, y, params=dict()):\n",
    "        if X.shape[1]!=len(y):\n",
    "            X = X.transpose()\n",
    "        # add intercept\n",
    "        X = np.insert(X, 0, values=1, axis=0)\n",
    "        yX = y*X\n",
    "        self.optim = self.set_params('SGD', 'optimizer', params)\n",
    "        if self.optim == 'SGD':\n",
    "            self.SGD(X,y,yX,params)\n",
    "        elif self.optim == 'GD':\n",
    "            self.GD(X,y,yX,params)    \n",
    "        elif self.optim == 'SLGD':\n",
    "            self.SLGD(X,y,yX,params)\n",
    "        else:\n",
    "            raise NameError(self.optim)\n",
    "        \n",
    "        \n",
    "    def get_acc(self, X, y):\n",
    "        return ((self.predict(X) * y)>0).sum()/len(y)\n",
    "    \n",
    "    def set_params(self, default, label, params):\n",
    "        return default if label not in params.keys() else params[label]\n",
    "        \n",
    "    def GD(self,X, y, yX, params):\n",
    "        rounds = self.set_params(50, 'rounds', params)\n",
    "        decay = self.set_params(1.0, 'decay', params)\n",
    "        L2 = self.set_params(0.5, 'l2_ratio', params)\n",
    "        \n",
    "        rnd = tqdm.trange(rounds, desc='Logisitic GD')            \n",
    "        for i in rnd:\n",
    "            dloss =  np.dot((self.h(yX)-1),yX.transpose())\n",
    "            dloss if L2 == 0 else dloss + L2 * self.theta\n",
    "            self.theta = self.theta - self.alpha * dloss\n",
    "            self.acc = self.get_acc(X,y)\n",
    "            rnd.set_description('Logistic GD (acc=%g)' % self.acc)\n",
    "            self.alpha *= decay\n",
    "        \n",
    "    \n",
    "    def SGD(self, X, y, yX, params):\n",
    "        rounds = self.set_params(50, 'rounds', params)\n",
    "        batchsize = self.set_params(32, 'batchsize', params)\n",
    "        decay = self.set_params(1.0, 'decay', params)\n",
    "        L2 = self.set_params(0.5, 'l2_ratio', params)\n",
    "        \n",
    "        num_item = yX.shape[1]\n",
    "        num_batch = num_item//batchsize\n",
    "        left_batch = num_item%batchsize\n",
    "        num_batch = num_batch if left_batch == 0 else num_batch+1\n",
    "        rnd = tqdm.trange(rounds, desc='Logisitic SGD')\n",
    "        for i in rnd:\n",
    "            shuffle = np.random.permutation(np.arange(num_item))\n",
    "            for b in range(num_batch):\n",
    "                if b!=num_batch-1:\n",
    "                    batch = yX[:,shuffle[b*batchsize:(b+1)*batchsize]]\n",
    "                else:\n",
    "                    batch = yX[:,shuffle[b*batchsize:]]\n",
    "                dloss = np.dot((self.h(batch)-1),batch.transpose())\n",
    "                dloss = dloss if L2 == 0 else dloss + L2 * self.theta\n",
    "                self.theta = self.theta - self.alpha * dloss\n",
    "                \n",
    "            self.acc = self.get_acc(X,y)\n",
    "            rnd.set_description('Logistic SGD (acc=%g)' % self.acc)\n",
    "            self.alpha *= decay    \n",
    "    \n",
    "    def SLGD(self, X, y, yX, params):\n",
    "        rounds = self.set_params(50, 'rounds', params)\n",
    "        batchsize = self.set_params(32, 'batchsize', params)\n",
    "        decay = self.set_params(0.99, 'decay', params)\n",
    "        \n",
    "        num_item = yX.shape[1]\n",
    "        num_batch = num_item//batchsize\n",
    "        left_batch = num_item%batchsize\n",
    "        num_batch = num_batch if left_batch == 0 else num_batch+1\n",
    "        rnd = tqdm.trange(rounds, desc='Logisitic SLGD')\n",
    "        for i in rnd:\n",
    "            shuffle = np.random.permutation(np.arange(num_item))\n",
    "            for b in range(num_batch):\n",
    "                if b!=num_batch-1:\n",
    "                    batch = yX[:,shuffle[b*batchsize:(b+1)*batchsize]]\n",
    "                else:\n",
    "                    batch = yX[:,shuffle[b*batchsize:]]\n",
    "                dloss = np.dot((self.h(batch)-1),batch.transpose())\n",
    "                # variance for Langevin Noise term is sqrt(lr)\n",
    "                dloss = dloss + np.sqrt(self.alpha) * np.random.randn(self.dim)\n",
    "                self.theta = self.theta - self.alpha * dloss\n",
    "                \n",
    "            self.acc = self.get_acc(X,y)\n",
    "            rnd.set_description('Logistic SLGD (acc=%g)' % self.acc)\n",
    "            self.alpha *= decay    \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        if X.shape[0]!=self.dim and X.shape[0]!=self.dim-1:\n",
    "            X = X.transpose()\n",
    "        if X.shape[0]==self.dim-1:\n",
    "            X = np.insert(X, 0, values=1, axis=0)            \n",
    "        pred = self.h(X)\n",
    "        pred[pred<0.5] = -1\n",
    "        pred[pred>=0.5] = 1\n",
    "        return pred.astype(int)\n",
    "    \n",
    "    def get_score(self, X):\n",
    "        if X.shape[0]!=self.dim and X.shape[0]!=self.dim-1:\n",
    "            X = X.transpose()\n",
    "        if X.shape[0]==self.dim-1:\n",
    "            X = np.insert(X, 0, values=1, axis=0)            \n",
    "        pred = self.h(X)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note & Reference:\n",
    "\n",
    "For the Langevin Dynamics Optimization Strategy, I refered the blog \n",
    "https://henripal.github.io/blog/langevin and a ICML 2011 paper, \n",
    "[Bayesian Learning via Stochastic Gradient Langevin Dynamics](https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = db['target']\n",
    "X = db['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic SGD (acc=0.922671): 100%|██████████| 2000/2000 [00:02<00:00, 749.57it/s]\n"
     ]
    }
   ],
   "source": [
    "M = logisticRegression(30,1.)\n",
    "\n",
    "params = {\n",
    "    'rounds':2000,\n",
    "    'optimizer':'SGD', \n",
    "    'l2_ratio':0.1, \n",
    "    'decay':0.99,\n",
    "    'batchsize':32,\n",
    "}\n",
    "\n",
    "M.fit(X,y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic SLGD (acc=0.927944): 100%|██████████| 2000/2000 [00:02<00:00, 806.41it/s]\n"
     ]
    }
   ],
   "source": [
    "M = logisticRegression(30,1.)\n",
    "\n",
    "params = {\n",
    "    'rounds':2000,\n",
    "    'optimizer':'SLGD', \n",
    "    'decay':0.999,\n",
    "    'batchsize':32,\n",
    "}\n",
    "\n",
    "M.fit(X,y, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000000e+000 1.000000e+000 0.000000e+000 0.000000e+000 1.000000e+000\n",
      " 0.000000e+000 1.000000e+000 4.323322e-245 1.000000e+000 1.000000e+000\n",
      " 1.000000e+000 1.000000e+000 1.000000e+000 0.000000e+000 0.000000e+000\n",
      " 1.000000e+000 0.000000e+000 0.000000e+000 1.000000e+000 1.000000e+000]\n",
      "[-1  1 -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1 -1  1  1]\n",
      "[-1 -1 -1 -1 -1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(M.get_score(X)[40:60])\n",
    "print(M.predict(X)[40:60])\n",
    "print(y[40:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(X.transpose(),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9595782073813708"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.predict(X.transpose())==y).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.insert(a, 0, values=1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ,  1.        ],\n",
       "       [ 0.47978646,  1.06847799,  2.11185544, -0.18527605],\n",
       "       [-0.49934084,  0.68689142,  0.08187441, -0.53404991]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
